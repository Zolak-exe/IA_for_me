# ğŸ¤– SystÃ¨me Multi-Agents Auto-Correctif

Un systÃ¨me autonome qui orchestre 6 agents IA spÃ©cialisÃ©s pour gÃ©nÃ©rer, vÃ©rifier, tester, sÃ©curiser et documenter un projet complet.

## âœ¨ CaractÃ©ristiques

- **6 agents spÃ©cialisÃ©s**: Architecte, DÃ©veloppeur, Reviewer, SÃ©curitÃ©, Testeur, Documentation
- **Boucle d'amÃ©lioration continue**: Jusqu'Ã  15 itÃ©rations pour atteindre la qualitÃ© cible
- **ExÃ©cution 100% locale**: Utilise Ollama pour les modÃ¨les LLM locaux
- **CritÃ¨res d'arrÃªt intelligents**: DÃ©tecte stagnation, qualitÃ© atteinte, etc.
- **Export complet**: Architecture, code, tests, sÃ©curitÃ©, documentation
- **Rapports dÃ©taillÃ©s**: MÃ©triques, scores, problÃ¨mes dÃ©tectÃ©s

## ğŸ—ï¸ Architecture

```
Multi-Agent System
â”œâ”€â”€ ğŸ‘¨â€ğŸ’¼ ArchitectAgent: Conception architecture hexagonale
â”œâ”€â”€ ğŸ‘¨â€ğŸ’» DeveloperAgent: GÃ©nÃ©ration de code professionnel
â”œâ”€â”€ ğŸ” ReviewerAgent: Audit qualitÃ© et best practices
â”œâ”€â”€ ğŸ”’ SecurityAgent: Audit OWASP et vulnÃ©rabilitÃ©s
â”œâ”€â”€ âœ… TesterAgent: GÃ©nÃ©ration tests unitaires
â””â”€â”€ ğŸ“š DocumentationAgent: Documentation complÃ¨te

Orchestrateur
â”œâ”€â”€ GÃ¨re le workflow itÃ©ratif
â”œâ”€â”€ Calcule score global pondÃ©rÃ©
â”œâ”€â”€ DÃ©tecte critÃ¨res d'arrÃªt
â””â”€â”€ Sauvegarde meilleure solution
```

## ğŸ“‹ PrÃ©requis

### 1. Installer Ollama

**Windows:**
```powershell
# TÃ©lÃ©charger depuis https://ollama.ai
# Ou utiliser winget
winget install Ollama.Ollama
```

**Linux:**
```bash
curl -fsSL https://ollama.ai/install.sh | sh
```

### 2. TÃ©lÃ©charger des modÃ¨les

```bash
# ModÃ¨les recommandÃ©s
ollama pull mistral:latest          # LÃ©ger et performant
ollama pull neural-chat:latest      # Bon rapport qualitÃ©/taille
ollama pull codellama:13b           # Pour la gÃ©nÃ©ration code

# OU si tu as de la VRAM disponible
ollama pull codellama:34b
ollama pull deepseek-coder:33b
ollama pull qwen2.5-coder:32b
```

VÃ©rifier les modÃ¨les:
```bash
ollama list
```

### 3. Lancer Ollama

```bash
# Par dÃ©faut sur http://localhost:11434
ollama serve

# Windows: Ollama lance un service en arriÃ¨re-plan
```

### 4. Python 3.10+

```bash
python --version  # VÃ©rifier
```

## ğŸš€ Installation

### 1. Cloner/Copier le projet

```bash
cd h:\DevAI\multi-agent-system
```

### 2. CrÃ©er un environnement virtuel

```powershell
python -m venv venv
.\venv\Scripts\Activate.ps1
```

### 3. Installer les dÃ©pendances

```bash
pip install -r requirements.txt
```

## ğŸ’» Utilisation

### Utilisation simple

```bash
python main.py --requirements "CrÃ©er une API REST en Python avec FastAPI"
```

### Avec options avancÃ©es

```bash
python main.py \
  --requirements "CrÃ©er un CLI tool pour gÃ©rer des tÃ¢ches" \
  --max-iterations 10 \
  --threshold 85 \
  --output ./mon-projet \
  --verbose
```

### Options disponibles

```
--requirements TEXT         âœ“ Description du projet (obligatoire)
--max-iterations INT        Nombre max d'itÃ©rations (dÃ©faut: 15)
--threshold FLOAT          Seuil de qualitÃ© 0-100 (dÃ©faut: 90)
--output PATH              Dossier rÃ©sultats (dÃ©faut: ./outputs)
--verbose                  Affichage DEBUG dÃ©taillÃ©
```

## ğŸ“Š RÃ©sultats

La sortie sera dans `./outputs/project_YYYYMMDD_HHMMSS/`:

```
project_20240315_143022/
â”œâ”€â”€ SUMMARY.json           # RÃ©sumÃ© exÃ©cution
â”œâ”€â”€ METRICS.json           # MÃ©triques itÃ©rations
â”œâ”€â”€ ARCHITECTURE.md        # Design et patterns
â”œâ”€â”€ CODE.md               # Code source gÃ©nÃ©rÃ©
â”œâ”€â”€ TESTS.md              # Suite tests unitaires
â”œâ”€â”€ DOCUMENTATION.md      # Guide complet
â”œâ”€â”€ REPORT.txt            # Rapport texte
â””â”€â”€ REPORT.html           # Rapport HTML
```

## ğŸ¯ Exemple d'exÃ©cution

```bash
$ python main.py --requirements "API REST pour gestion de tÃ¢ches avec authentification JWT"

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘      ğŸ¤– SYSTÃˆME MULTI-AGENTS AUTO-CORRECTIF ğŸ¤–            â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ”Œ Initialisation client Ollama...
âœ… Connexion Ã  Ollama Ã©tablie
   Status: ok
   ModÃ¨les disponibles: 5

ğŸ—ï¸  Initialisation du systÃ¨me multi-agents...
   âœ“ 6 agents initialisÃ©s
     â€¢ Architecte (codellama:34b)
     â€¢ DÃ©veloppeur (deepseek-coder:33b)
     â€¢ Reviewer (qwen2.5-coder:32b)
     â€¢ SÃ©curitÃ© (llama2:13b)
     â€¢ Testeur (phind-coder:34b)
     â€¢ Documentation (mistral:7b)

ğŸ“‹ REQUIREMENTS:
   API REST pour gestion de tÃ¢ches avec authentification JWT

============================================================

ğŸ”„ ITÃ‰RATION 1/15
============================================================
ğŸ‘¨â€ğŸ’¼ Phase 1: Architecture...
ğŸ‘¨â€ğŸ’» Phase 2: DÃ©veloppement...
ğŸ” Phase 3: Revue qualitÃ©...
ğŸ”’ Phase 4: Audit sÃ©curitÃ©...
âœ… Phase 5: GÃ©nÃ©ration tests...
ğŸ“š Phase 6: Documentation...

ğŸ“Š ITÃ‰RATION 1:
â”œâ”€ Score global: 72.3% 
â”œâ”€ QualitÃ© code: 68.5%
â”œâ”€ SÃ©curitÃ©: 75.2%
â”œâ”€ ProblÃ¨mes dÃ©tectÃ©s: 5
â”œâ”€ AmÃ©liorations: 3
â””â”€ Meilleur: 72.3% (itÃ©ration 1)

[ItÃ©rations 2-8: amÃ©lioration progressive...]

ğŸ”„ ITÃ‰RATION 9/15
============================================================
ğŸ“Š ITÃ‰RATION 9:
â”œâ”€ Score global: 92.1% 
â”œâ”€ QualitÃ© code: 91.0%
â”œâ”€ SÃ©curitÃ©: 93.5%
â”œâ”€ ProblÃ¨mes dÃ©tectÃ©s: 1
â”œâ”€ AmÃ©liorations: 0
â””â”€ Meilleur: 92.1% (itÃ©ration 9)

âœ… QualitÃ© 92.1% atteinte (seuil: 90%)

============================================================
ğŸ‰ RÃ‰SUMÃ‰ FINAL:
============================================================
âœ… ItÃ©rations exÃ©cutÃ©es: 9/15
âœ… Meilleur score: 92.1%
âœ… ItÃ©ration gagnante: 9
âœ… Solution exportÃ©e dans: ./outputs/project_20240315_143022
âœ… EXÃ‰CUTION COMPLÃ‰TÃ‰E AVEC SUCCÃˆS!
```

## âš™ï¸ Configuration

Voir `config/settings.py` pour personnaliser:

- **ModÃ¨les LLM** utilisÃ©s par chaque agent
- **ParamÃ¨tres gÃ©nÃ©ration** (tempÃ©rature, top_p, etc.)
- **CritÃ¨res d'arrÃªt** (seuil qualitÃ©, stagnation, etc.)
- **PondÃ©rations** du score global

## ğŸ“ˆ MÃ©triques et Scoring

### Score Global (pondÃ©rÃ©)

```
Score = (0.35 Ã— QualitÃ©) + (0.25 Ã— SÃ©curitÃ©) + (0.20 Ã— Tests) + (0.20 Ã— Docs)
```

### CritÃ¨res de qualitÃ©

- **QualitÃ© Code (0-100)**: ConformitÃ© architecture, lisibilitÃ©, best practices
- **SÃ©curitÃ© (0-100)**: Absence vulnÃ©rabilitÃ©s OWASP
- **Tests (0-100)**: PrÃ©sence tests unitaires, couverture
- **Documentation (0-100)**: ComplÃ©tude, clartÃ©

### ArrÃªt automatique

Le systÃ¨me s'arrÃªte si:
1. **Score â‰¥ 90%** (seuil par dÃ©faut)
2. **3 itÃ©rations sans amÃ©lioration** (stagnation)
3. **Max 15 itÃ©rations atteintes**

## ğŸ” DÃ©pannage

### Ollama ne rÃ©pond pas

```
âŒ Impossible de se connecter Ã  Ollama
   VÃ©rifiez que Ollama est running sur http://localhost:11434
```

**Solution:**
```bash
ollama serve
```

### Aucun modÃ¨le disponible

```
âš ï¸  Aucun modÃ¨le trouvÃ©
   TÃ©lÃ©charge au moins un modÃ¨le avec: ollama pull mistral
```

**Solution:**
```bash
ollama pull mistral:latest
ollama list  # VÃ©rifier
```

### Timeout (gÃ©nÃ©ration trop lente)

Augmente le timeout dans `config/settings.py`:
```python
OLLAMA_CONFIG = {
    "timeout": 600,  # 10 minutes au lieu de 5
}
```

Ou utilise des modÃ¨les plus lÃ©gers:
```python
AGENT_MODELS = {
    "architect": "mistral:7b",
    "developer": "mistral:7b",
    # ...
}
```

### MÃ©moire insuffisante

Si le GPU manque de VRAM:

1. RÃ©duire la taille des modÃ¨les
2. Utiliser modÃ¨les 7B au lieu de 34B
3. Laisser plus de mÃ©moire libre avant lancement

## ğŸ“š Documentation technique

### Structure agents

Tous les agents hÃ©ritent de `BaseAgent`:

```python
class ArchitectAgent(BaseAgent):
    def execute(self, requirements: str) -> AgentOutput:
        # ImplÃ©mentation spÃ©cifique
        pass
```

### Workflow itÃ©ratif

1. **Architecte** â†’ Conception architecture
2. **DÃ©veloppeur** â†’ Code selon architecture
3. **Reviewer** â†’ Score qualitÃ©
4. **SÃ©curitÃ©** â†’ VulnÃ©rabilitÃ©s
5. **Testeur** â†’ Tests unitaires
6. **Documentation** â†’ Docs
7. **Orchestrateur** â†’ Score global + dÃ©cision arrÃªt

### Sortie `AgentOutput`

```python
@dataclass
class AgentOutput:
    agent_name: str
    success: bool
    content: str
    score: Optional[float] = None
    issues: list = None
    recommendations: list = None
```

## ğŸ“ AmÃ©liorations futures

- [ ] Support GPU ROCm/CUDA pour accÃ©lÃ©ration
- [ ] Cache persistant des rÃ©sultats
- [ ] Parallel execution d'agents indÃ©pendants
- [ ] Web UI pour suivi en temps rÃ©el
- [ ] IntÃ©gration CI/CD
- [ ] Support multiples langages (Go, Rust, etc.)
- [ ] Analyse de coÃ»t en tokens
- [ ] Fine-tuning des prompts adaptatifs

## ğŸ“ License

MIT

## ğŸ‘¨â€ğŸ’» Support

Pour problÃ¨mes ou suggestions, voir les logs dans `system.log`
